{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROhUE1Yo_Eg5"
   },
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSzqkYIoukC1",
    "outputId": "fd77449c-cf1f-4e35-c12f-bce507d9edef"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import Counter\n",
    "import ast\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from datetime import datetime\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.exceptions import InvalidFileException\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer, \n",
    "    RobertaForSequenceClassification, \n",
    "    RobertaTokenizer, \n",
    "    RobertaModel, \n",
    "    AutoModel, \n",
    "    AutoTokenizer, \n",
    "    XLMRobertaForSequenceClassification, \n",
    "    XLMRobertaTokenizer,\n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    BertForSequenceClassification, \n",
    "    TrainerCallback\n",
    ")\n",
    "\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "import pyarrow as pa\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMobsuiYGmuQ",
    "outputId": "c48117ab-a7fb-4a50-a657-33073c55d624"
   },
   "outputs": [],
   "source": [
    "print('Downlowing stopwords...')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtdSgrIt-127"
   },
   "source": [
    "## FUNCIONES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgJLDbqrPcO0"
   },
   "source": [
    "Funciones que utilizamos para el preprocesamiento de los datos: remove_stopwords, stemming, stemming_turkish y clean\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "meAMVIV_JyjE"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text, language):\n",
    "\n",
    "    # Cargamos las stopwords\n",
    "    if language == 'english':\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "    elif language == 'spanish':\n",
    "            stop_words = set(stopwords.words('spanish'))\n",
    "    elif language == 'turkish':\n",
    "            stop_words = set(nltk.corpus.stopwords.words('turkish'))\n",
    "    else:\n",
    "      print('Language not supported')\n",
    "\n",
    "    # Eliminamos las stopwords\n",
    "    cleanTxt = [x for x in text.split() if x not in stop_words]\n",
    "    return ' '.join(cleanTxt)\n",
    "\n",
    "def stemming(text, language):\n",
    "    stemmer = SnowballStemmer(language)\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Definimos las función stemming para el turco\n",
    "def stemming_turkish(text):\n",
    "    stemmer_tr = snowballstemmer.stemmer('turkish')\n",
    "    words = text.split()\n",
    "    stemmed_words = [stemmer_tr.stemWord(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Define the cleaning function\n",
    "def clean(text, language):\n",
    "\n",
    "    if isinstance(text, str):\n",
    "        cleanTxt = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Eliminamos las URLs\n",
    "        cleanTxt = re.sub(r'#\\w+', '', cleanTxt)               # Eliminamos los hashtags\n",
    "        cleanTxt = re.sub(r'\\W+|\\d+', ' ', cleanTxt)           # Eliminamos los carácteres y números no alphanumericos and numbers\n",
    "        cleanTxt = cleanTxt.lower()                            # Minúsculas\n",
    "    else:\n",
    "        # Convertimos el elemento a cadena de texto\n",
    "        text = str(text)\n",
    "        cleanTxt = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Eliminamos las URLs\n",
    "        cleanTxt = re.sub(r'#\\w+', '', cleanTxt)               # Eliminamos los hashtags\n",
    "        cleanTxt = re.sub(r'\\W+|\\d+', ' ', cleanTxt)           # Eliminamos los carácteres y números no alphanumericos and numbers\n",
    "        cleanTxt = cleanTxt.lower()                            # Minúsculas\n",
    "        \n",
    "    # Stopwords \n",
    "    stop_words = set(stopwords.words(language))\n",
    "    cleanTxt = ' '.join([word for word in cleanTxt.split() if word not in stop_words])\n",
    "\n",
    "    # Stemming\n",
    "    if language == 'turkish':\n",
    "        cleanTxt = stemming_turkish(cleanTxt)\n",
    "    else:\n",
    "        cleanTxt = stemming(cleanTxt, language)\n",
    "\n",
    "    return cleanTxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUlY7P5hPFMd"
   },
   "outputs": [],
   "source": [
    "def load_data(path, task, language):\n",
    "    data = pd.read_csv(path, sep='\\t')\n",
    "\n",
    "    if language == 'english':\n",
    "        data = data[data['language'] == 'en']\n",
    "\n",
    "    elif language == 'spanish':\n",
    "        data = data[data['language'] == 'es']\n",
    "\n",
    "    else:\n",
    "      print('not supported')\n",
    "\n",
    "    data['text']  = data['text'].apply(clean, language=language)\n",
    "    data = pd.DataFrame({'text': data['text'], 'label': data[task]})     \n",
    "    if task == 'task1':\n",
    "        data['label']  = data['label'].map({'sexist': 1, 'non-sexist': 0})  # Convertimos en una variable binaria\n",
    "\n",
    "    if task == 'task2':\n",
    "        data['label']  = data['label'].map({'ideological-inequality': 1,    # Convertimos en 6 clases numéricas\n",
    "                                            'stereotyping-dominance': 2,\n",
    "                                            'objectification': 3,\n",
    "                                            'sexual-violence': 4,\n",
    "                                            'misogyny-non-sexual-violence': 5,\n",
    "                                            'non-sexist': 0})\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Cargamos el dataset turco\n",
    "def load_turkish_data(path, task, language):\n",
    "    df_exist_turkish = pd.read_csv(path, delimiter=';')\n",
    "    df_exist_turkish = df_exist_turkish.rename(columns={\n",
    "        'Annotation_L1_Eng': 'task1',\n",
    "        'Annotation_L2_Eng': 'task2',\n",
    "        'Annotation_L1_TR': 'task1_tr',\n",
    "        'Annotation_L2_TR': 'task2_tr',\n",
    "        'Text': 'text'\n",
    "    })\n",
    "\n",
    "    # Convertimos todos los elementos a minúsculas\n",
    "    df_exist_turkish = df_exist_turkish.apply(lambda col: col.map(lambda x: x.lower() if isinstance(x, str) else x))\n",
    "\n",
    "    # Añadimos la columna del idioma\n",
    "    df_exist_turkish['language'] = 'tr'\n",
    "\n",
    "    # Renombramos para unificar los datasets\n",
    "    replacements = {\n",
    "        'not-sexist': 'non-sexist',\n",
    "        'anti-feminism': 'ideological-inequality',\n",
    "        'misogyny': 'misogyny-non-sexual-violence',\n",
    "        'sexual_violence': 'sexual-violence',\n",
    "        'stereotyping': 'stereotyping-dominance'\n",
    "    }\n",
    "    df_exist_turkish.replace(replacements, inplace=True)\n",
    "\n",
    "    # Eliminamos las columnas innecesarias\n",
    "    df_exist_turkish.drop(['task1_tr', 'task2_tr', 'ID'], axis=1, inplace=True)\n",
    "\n",
    "    df_exist_turkish['text'] = df_exist_turkish['text'].apply(lambda x: clean(x, language))\n",
    "\n",
    "    data = pd.DataFrame({'text': df_exist_turkish['text'], 'label': df_exist_turkish[task]})        \n",
    "    if task == 'task1':\n",
    "        data['label']  = data['label'].map({'sexist': 1, 'non-sexist': 0})  # Convertimos en una variable binaria\n",
    "\n",
    "    if task == 'task2':\n",
    "        data['label']  = data['label'].map({'ideological-inequality': 1,    # Convertimos en 6 clases numéricas\n",
    "                                            'stereotyping-dominance': 2,\n",
    "                                            'objectification': 3,\n",
    "                                            'sexual-violence': 4,\n",
    "                                            'misogyny-non-sexual-violence': 5,\n",
    "                                            'non-sexist': 0})\n",
    "\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cutNPjAQE8j"
   },
   "outputs": [],
   "source": [
    "# Cargamos los diferentes tokenizadores\n",
    "\n",
    "tokenizer_en = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tokenizer_es = RobertaTokenizer.from_pretrained(\"PlanTL-GOB-ES/roberta-base-bne\")\n",
    "\n",
    "# Funcion que tokeniza los modelos segín el idioma\n",
    "def tokenization(batched_text, language):\n",
    "    if language == 'english':\n",
    "        return tokenizer_en(batched_text['text'], padding=True, truncation=True)\n",
    "\n",
    "    elif language == 'spanish':\n",
    "        return tokenizer_es(batched_text['text'], padding=True, truncation=True)\n",
    "\n",
    "    elif language == 'turkish':\n",
    "        return tokenizer_tr(batched_text['text'], padding=True, truncation=True)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Language not supported\")\n",
    "\n",
    "def formatting_data(df, language):\n",
    "    data = Dataset(pa.Table.from_pandas(df))                                    # Convertimos el DataFrame en un conjunto de datos de Huggingface\n",
    "    data = data.map(lambda batch: tokenization(batch, language), batched=True, batch_size=len(data))  # Aplicamos la funcion tokenizador\n",
    "    data.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])  # Establecemos el formato\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSK6OUuNJyjF"
   },
   "source": [
    "Creamos una función para guardar los datos en excels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zh-CVJrW8Tpl"
   },
   "outputs": [],
   "source": [
    "class SaveMetricsCallback(TrainerCallback):\n",
    "    def __init__(self, file_name):\n",
    "        self.metrics_data = []\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        # Guardamos las métricas después de cada epoch\n",
    "        if metrics is not None:\n",
    "            self.metrics_data.append(metrics)\n",
    "\n",
    "    def save_to_excel(self):\n",
    "        # Creamos un DataFrame con las métricas\n",
    "        df = pd.DataFrame(self.metrics_data)\n",
    "\n",
    "        # Definimos la ruta\n",
    "        file_path = f'{self.file_name}.xlsx'\n",
    "        valor = random.random()\n",
    "        sheet_name = f\"hoja_{valor}\"\n",
    "\n",
    "        try:\n",
    "            # Cargamos el libro existente\n",
    "            try:\n",
    "                book = load_workbook(file_path)\n",
    "                # Verificamos si la hoja existe\n",
    "                if sheet_name in book.sheetnames:\n",
    "                    # Si la hoja existe la eliminamos\n",
    "                    del book[sheet_name]\n",
    "                    book.save(file_path)\n",
    "                # Guardamos los datos\n",
    "                with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "                    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            except (FileNotFoundError, InvalidFileException, KeyError):\n",
    "                # Si el libro no se puede cargar o está vacío, creamos uno nuevo\n",
    "                with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "                    df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "            print(f\"Datos guardados en el archivo '{self.file_name}.xlsx'.\")\n",
    "\n",
    "        except PermissionError:\n",
    "            print(f\"Error: No se pudo acceder o guardar en '{self.file_name}.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_z1j2rxWRWl"
   },
   "source": [
    "Función auxiliar que imprime las métricas que analizaremos en nuestro modelo y nos ayudará a sacar conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "krZiqLXytq1f"
   },
   "outputs": [],
   "source": [
    "def metrics(predicted):\n",
    "    labels = predicted.label_ids\n",
    "    predictions = predicted.predictions.argmax(-1)\n",
    "\n",
    "    #Calcula la precisión del clasificador\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    print('Accuracy:', accuracy)\n",
    "\n",
    "    report = classification_report(labels, predictions, output_dict=True, zero_division=0)\n",
    "    precision_per_class = {label: metrics['precision'] for label, metrics in report.items() if isinstance(metrics, dict)}\n",
    "    recall_per_class = {label: metrics['recall'] for label, metrics in report.items() if isinstance(metrics, dict)}\n",
    "    f1_score_per_class = {label: metrics['f1-score'] for label, metrics in report.items() if isinstance(metrics, dict)}\n",
    "\n",
    "    precision = report['weighted avg']['precision']\n",
    "    recall = recall_score(labels, predictions, average='macro', zero_division=0)\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "   \n",
    "    return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmDqKC0etj8P"
   },
   "source": [
    "## ROBERTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsei2pyDKEYD"
   },
   "source": [
    "### task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPt4fEKHQoyz"
   },
   "source": [
    "## Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kkyMZBv_DYC",
    "outputId": "19d2d52a-4dbb-4d27-a3b0-83c1c2792eb0"
   },
   "outputs": [],
   "source": [
    "# english\n",
    "train_load_en = load_data(\"EXIST_training.tsv\", 'task1', 'english')\n",
    "test_load_en = load_data(\"EXIST_test_labeled.tsv\", 'task1', 'english')\n",
    "#spanish\n",
    "train_load_es = load_data(\"EXIST_training.tsv\", 'task1', 'spanish')\n",
    "test_load_es = load_data(\"EXIST_test_labeled.tsv\",  'task1', 'spanish')\n",
    "#turkish\n",
    "df_exist_turkish = load_turkish_data(\"Dataset_Sexism_Turkish.csv\",  'task1', 'turkish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OkiQouWNJyjG"
   },
   "outputs": [],
   "source": [
    "#separamos el dataset en training y test set\n",
    "train_load_tr, test_load_tr = train_test_split(df_exist_turkish, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1yuVfd6rJyjG"
   },
   "outputs": [],
   "source": [
    "train_load_en , validation_load_en  = train_test_split(train_load_en , test_size=0.2, random_state=42) #english\n",
    "train_load_es , validation_load_es  = train_test_split(train_load_es , test_size=0.2, random_state=42) #spanish\n",
    "train_load_tr , validation_load_tr  = train_test_split(train_load_tr , test_size=0.2, random_state=42) #turkish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QifwILUiSKgs",
    "outputId": "60b87dff-37df-479a-e1fb-06da63ce1534"
   },
   "outputs": [],
   "source": [
    "#english\n",
    "train_en = formatting_data(train_load_en, 'english')\n",
    "test_en  = formatting_data(train_load_en, 'english' )\n",
    "validation_en = formatting_data(validation_load_en, 'english' )\n",
    "\n",
    "#spanish\n",
    "train_es = formatting_data(train_load_es, 'spanish' )\n",
    "test_es  = formatting_data(test_load_es, 'spanish' )\n",
    "validation_es = formatting_data(validation_load_es, 'spanish' )\n",
    "\n",
    "#turkish\n",
    "train_tr = formatting_data(train_load_tr, 'turkish' )\n",
    "test_tr  = formatting_data(test_load_tr, 'turkish' )\n",
    "validation_tr = formatting_data(validation_load_tr, 'turkish' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzOtp1NstraU",
    "outputId": "cea028e4-5621-40a8-b1b5-a0c8c1c243d9"
   },
   "outputs": [],
   "source": [
    "# Cargamos el english model\n",
    "model_en = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "\n",
    "# Cargamos el spanish model\n",
    "model_es = RobertaForSequenceClassification.from_pretrained(\"PlanTL-GOB-ES/roberta-base-bne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXYsjxTJtrQd"
   },
   "outputs": [],
   "source": [
    "# Definimos los arumentos de entrenamientos de los modelos \n",
    "training_args = TrainingArguments(\n",
    "    output_dir='RESULTADOS',\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_strategy='steps',  # Para una evaluación más frecuente\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=3e-5,  # Tasa de aprendizaje\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,  \n",
    "    num_train_epochs=10, \n",
    "    weight_decay=0.1, \n",
    "    logging_dir='LOGS',\n",
    "    logging_steps=100,  \n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=3,  # Limitamos el número de modelos guardados\n",
    "    gradient_accumulation_steps=2,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9GbyNfsdGXG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Metricas\n",
    "metrics_callback = SaveMetricsCallback(file_name='training_metrics_roberta_t1_en')\n",
    "\n",
    "# Trainer class\n",
    "trainer_en = Trainer(\n",
    "    model=model_en,\n",
    "    args=training_args,\n",
    "    compute_metrics=metrics,\n",
    "    train_dataset=train_en,\n",
    "    eval_dataset=validation_en,\n",
    "    callbacks=[metrics_callback]\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo\n",
    "print('\\n* TRAIN *\\n')\n",
    "trainer_en.train()\n",
    "\n",
    "# Evaluamos el modelo\n",
    "print('\\n* EVALUATE *\\n')\n",
    "trainer_en.evaluate(test_en)\n",
    "\n",
    "# Guardamos las métricas\n",
    "metrics_callback.save_to_excel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-1-YIONJyjH"
   },
   "outputs": [],
   "source": [
    "# Guardamos el modelo y el tokenizador\n",
    "model_name = 'saved_roberta_model_task1_en'\n",
    "model_en.save_pretrained(model_name)\n",
    "tokenizer_en.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OZyq2EAMGSeO"
   },
   "outputs": [],
   "source": [
    "metrics_callback = SaveMetricsCallback(file_name='training_metrics_roberta_t1_es')\n",
    "\n",
    "trainer_es= Trainer(\n",
    "    model=model_es,\n",
    "    args=training_args,\n",
    "    compute_metrics=metrics,\n",
    "    train_dataset=train_es,\n",
    "    eval_dataset=validation_es,\n",
    "    callbacks=[metrics_callback]\n",
    ")\n",
    "\n",
    "# Entrenamos el model\n",
    "print('\\n* TRAIN *\\n')\n",
    "trainer_es.train()\n",
    "\n",
    "# Evaluamos el modelo\n",
    "print('\\n* EVALUATE *\\n')\n",
    "trainer_es.evaluate(test_es)\n",
    "\n",
    "# Guardamos las métricas\n",
    "metrics_callback.save_to_excel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IE-80_a2ePq0"
   },
   "outputs": [],
   "source": [
    "# Guardamos el modelo y el tokenizador\n",
    "model_name = 'saved_roberta_model_task1_es'\n",
    "model_es.save_pretrained(model_name)\n",
    "tokenizer_es.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nODUxI_XeZdP"
   },
   "source": [
    "### task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C085codEH9xN"
   },
   "source": [
    "## Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-SEoV_UJyjI"
   },
   "outputs": [],
   "source": [
    "# english\n",
    "train_load_en = load_data(\"EXIST_training.tsv\", 'task2', 'english')\n",
    "test_load_en = load_data(\"EXIST_test_labeled.tsv\", 'task2', 'english')\n",
    "#spanish\n",
    "train_load_es = load_data(\"EXIST_training.tsv\", 'task2', 'spanish')\n",
    "test_load_es = load_data(\"EXIST_test_labeled.tsv\",  'task2', 'spanish')\n",
    "#turkish\n",
    "df_exist_turkish = load_turkish_data(\"Dataset_Sexism_Turkish.csv\",  'task2', 'turkish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7RXX0xguJyjN"
   },
   "outputs": [],
   "source": [
    "#separamos el dataset en training y test set\n",
    "train_load_tr, test_load_tr = train_test_split(df_exist_turkish, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "no1bnMCjH9xt"
   },
   "outputs": [],
   "source": [
    "train_load_en , validation_load_en  = train_test_split(train_load_en , test_size=0.2, random_state=42) #english\n",
    "train_load_es , validation_load_es  = train_test_split(train_load_es , test_size=0.2, random_state=42) #spanish\n",
    "train_load_tr , validation_load_tr  = train_test_split(train_load_tr , test_size=0.2, random_state=42) #turkish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ld7RgAriH9xu"
   },
   "outputs": [],
   "source": [
    "#english\n",
    "train_en = formatting_data(train_load_en, 'english' )\n",
    "test_en  = formatting_data(test_load_en, 'english' )\n",
    "validation_en = formatting_data(validation_load_en, 'english' )\n",
    "\n",
    "\n",
    "#spanish\n",
    "train_es = formatting_data(train_load_es, 'spanish' )\n",
    "test_es  = formatting_data(test_load_es, 'spanish' )\n",
    "validation_es = formatting_data(validation_load_es, 'spanish' )\n",
    "\n",
    "\n",
    "#turkish\n",
    "train_tr = formatting_data(train_load_tr, 'turkish')\n",
    "test_tr  = formatting_data(test_load_tr, 'turkish')\n",
    "validation_tr = formatting_data(validation_load_tr, 'turkish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YafMh3fAH9xv"
   },
   "outputs": [],
   "source": [
    "# Cargamos el english model\n",
    "model_en = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "\n",
    "# Cargamos el spanish model\n",
    "model_es = RobertaForSequenceClassification.from_pretrained(\"PlanTL-GOB-ES/roberta-base-bne\")v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yp4Xpq_oH9xw"
   },
   "outputs": [],
   "source": [
    "training_args_2 = TrainingArguments(\n",
    "    output_dir='RESULTADOS',\n",
    "    evaluation_strategy='epoch',\n",
    "    logging_strategy='steps', \n",
    "    save_strategy='epoch',\n",
    "    learning_rate=3e-5, \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,  \n",
    "    num_train_epochs=10,  \n",
    "    weight_decay=0.1,\n",
    "    logging_dir='LOGS',\n",
    "    logging_steps=100, \n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    greater_is_better=True,\n",
    "    save_total_limit=3,  \n",
    "    gradient_accumulation_steps=2,  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YFEkYla8H9xx"
   },
   "outputs": [],
   "source": [
    "metrics_callback = SaveMetricsCallback(file_name='training_metrics_roberta_t2_en')\n",
    "\n",
    "trainer_en = Trainer(\n",
    "    model=model_en,\n",
    "    args=training_args_2,\n",
    "    compute_metrics=metrics,\n",
    "    train_dataset=train_en,\n",
    "    eval_dataset=validation_en,\n",
    "    callbacks=[metrics_callback]\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo\n",
    "print('\\n* TRAIN *\\n')\n",
    "trainer_en.train()\n",
    "\n",
    "# Evaluamos el modelo\n",
    "print('\\n* EVALUATE *\\n')\n",
    "trainer_en.evaluate(test_en)\n",
    "\n",
    "# Guardamos las métricas\n",
    "metrics_callback.save_to_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpD1TvvsJyjO"
   },
   "outputs": [],
   "source": [
    "# Guardamos el modelo y eltokenizador\n",
    "model_name = 'saved_roberta_model_task2_en'\n",
    "model_en.save_pretrained(model_name)\n",
    "tokenizer_en.save_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGAi-OHaH9xx"
   },
   "outputs": [],
   "source": [
    "metrics_callback = SaveMetricsCallback(file_name='training_metrics_roberta_t2_es')\n",
    "\n",
    "trainer_es = Trainer(\n",
    "    model=model_es,\n",
    "    args=training_args_2,\n",
    "    compute_metrics=metrics,\n",
    "    train_dataset=train_es,\n",
    "    eval_dataset=validation_es,\n",
    "    callbacks=[metrics_callback]\n",
    ")\n",
    "\n",
    "# Entrenamos el modelo\n",
    "print('\\n* TRAIN *\\n')\n",
    "trainer_es.train()\n",
    "\n",
    "# Evaluamos el modelo\n",
    "print('\\n* EVALUATE *\\n')\n",
    "trainer_es.evaluate(test_es)\n",
    "\n",
    "# Guardamos las métricas\n",
    "metrics_callback.save_to_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s25h0b6CH9xy"
   },
   "outputs": [],
   "source": [
    "# Guardamos el modelo y el tokenizador\n",
    "model_name = 'saved_roberta_model_task2_es'\n",
    "model_es.save_pretrained(model_name)\n",
    "tokenizer_es.save_pretrained(model_name)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
